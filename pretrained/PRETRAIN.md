1. Download the contents of the `Pretrained` folder from <a href="https://pan.baidu.com/s/1L-43y9SFDKmgl3dJNRlvNA?pwd=d3qj" title="model">FlexHook_best</a> (This link points to the anonymous cloud storage of FlexHook's weights and preprocessed public dataset for reproducing the model mentioned in the paper, and does not include any contributions beyond those mentioned in the paper)

2. Place pretrained weights in folder here as follows, or manually download the corresponding pretrained models from HuggingFace and <a href="https://github.com/naver-ai/rope-vit">ROPE-ViT</a> (Note: ROPE-ViT url here is a public model and is not the contribution of this paper).

```
FlexHook
├── pretrained
  ├── bert-base-uncased
  ├── CLIP
  ├── roberta-base
  ├── swin_rope_mixed_tiny_patch4_window7_224
...
```